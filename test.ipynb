{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset,random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 2000 samples for language 0 and 2000 samples for language 1.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-11.512925 , -11.512925 , -11.512925 , ..., -11.512925 ,\n",
       "        -11.512925 , -11.512925 ],\n",
       "       [-11.512925 , -11.512925 , -11.512925 , ..., -11.512925 ,\n",
       "        -11.512925 , -11.512925 ],\n",
       "       [-11.512925 , -11.512925 , -11.512925 , ..., -11.512925 ,\n",
       "        -11.512925 , -11.512925 ],\n",
       "       ...,\n",
       "       [ -5.672583 ,  -6.862608 ,  -6.7738132, ...,  -6.6783767,\n",
       "         -7.703056 ,  -8.840825 ],\n",
       "       [ -6.2198935,  -6.979812 ,  -6.4984074, ...,  -6.659245 ,\n",
       "         -7.500062 ,  -8.744839 ],\n",
       "       [ -6.584874 ,  -7.218131 ,  -7.068345 , ...,  -6.657686 ,\n",
       "         -7.625363 ,  -8.85662  ]], dtype=float32)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_npy_data_with_labels(folder_path, label):\n",
    "    data_list = []  # 用于存储所有读取的数据\n",
    "    labels_list = []  # 用于存储所有的标签\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.npy'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data = np.load(file_path)\n",
    "            data_list.append(data)\n",
    "            labels_list.append(label)\n",
    "    return data_list, labels_list\n",
    "\n",
    "# 使用你的文件夹路径替换这里\n",
    "base_folder_path = 'train_data'  # e.g., 'path_to_your_data/train_data'\n",
    "\n",
    "# 加载 language_0 的数据并分配标签 0\n",
    "language_0_folder_path = os.path.join(base_folder_path, 'language_0')\n",
    "language_0_data, language_0_labels = load_npy_data_with_labels(language_0_folder_path, 0)\n",
    "\n",
    "# 加载 language_1 的数据并分配标签 1\n",
    "language_1_folder_path = os.path.join(base_folder_path, 'language_1')\n",
    "language_1_data, language_1_labels = load_npy_data_with_labels(language_1_folder_path, 1)\n",
    "\n",
    "# 合并两种语言的数据和标签\n",
    "train_data_raw = language_0_data + language_1_data\n",
    "train_labels = language_0_labels + language_1_labels\n",
    "train_data_cropped = [matrix[:40] for matrix in train_data_raw]\n",
    "def min_max_normalize(tensor):\n",
    "    min_val = torch.min(tensor)\n",
    "    max_val = torch.max(tensor)\n",
    "    normalized_tensor = (tensor - min_val) / (max_val - min_val)\n",
    "    return normalized_tensor\n",
    "def standardize(tensor):\n",
    "    mean = torch.mean(tensor)\n",
    "    std = torch.std(tensor)\n",
    "    standardized_tensor = (tensor - mean) / std\n",
    "    return standardized_tensor\n",
    "# 打印出一些信息来确认数据已被加载\n",
    "print(f\"Loaded {len(language_0_data)} samples for language 0 and {len(language_1_data)} samples for language 1.\")\n",
    "train_data_cropped[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\蒋壮壮\\AppData\\Local\\Temp\\ipykernel_14904\\380450766.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:264.)\n",
      "  train_dataset = TensorDataset(standardize(torch.tensor(train_data_cropped)), torch.tensor(train_labels))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.5467, -0.5467, -0.5467,  ..., -0.5467, -0.5467, -0.5467],\n",
       "         [-0.5467, -0.5467, -0.5467,  ..., -0.5467, -0.5467, -0.5467],\n",
       "         [-0.5467, -0.5467, -0.5467,  ..., -0.5467, -0.5467, -0.5467],\n",
       "         ...,\n",
       "         [ 2.6199,  2.3542,  2.2991,  ...,  1.2457,  1.2652,  1.2718],\n",
       "         [ 2.6727,  2.3404,  1.9967,  ...,  1.1394,  1.0364,  0.9644],\n",
       "         [ 2.5546,  2.1321,  1.9312,  ...,  1.0189,  0.8640,  0.5961]]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 创建 TensorDataset 和 DataLoader\n",
    "train_dataset = TensorDataset(standardize(torch.tensor(train_data_cropped)), torch.tensor(train_labels))\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "\n",
    "# 随机分割成训练集和验证集\n",
    "train_dataset, val_dataset = random_split(train_dataset, [train_size, val_size])\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader=DataLoader(val_dataset,batch_size=64,shuffle=True)\n",
    "train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200, Loss: 0.7016828060150146\n",
      "Accuracy of the model on the validation data: 48.12 %\n",
      "Epoch 2/200, Loss: 0.7181267142295837\n",
      "Accuracy of the model on the validation data: 48.12 %\n",
      "Epoch 3/200, Loss: 0.7004460692405701\n",
      "Accuracy of the model on the validation data: 65.25 %\n",
      "Epoch 4/200, Loss: 0.6730477809906006\n",
      "Accuracy of the model on the validation data: 70.88 %\n",
      "Epoch 5/200, Loss: 0.6367615461349487\n",
      "Accuracy of the model on the validation data: 74.62 %\n",
      "Epoch 6/200, Loss: 0.6273844838142395\n",
      "Accuracy of the model on the validation data: 80.25 %\n",
      "Epoch 7/200, Loss: 0.5981584787368774\n",
      "Accuracy of the model on the validation data: 82.25 %\n",
      "Epoch 8/200, Loss: 0.6228981614112854\n",
      "Accuracy of the model on the validation data: 82.62 %\n",
      "Epoch 9/200, Loss: 0.6266378164291382\n",
      "Accuracy of the model on the validation data: 85.50 %\n",
      "Epoch 10/200, Loss: 0.5739012360572815\n",
      "Accuracy of the model on the validation data: 86.25 %\n",
      "Epoch 11/200, Loss: 0.5736496448516846\n",
      "Accuracy of the model on the validation data: 87.62 %\n",
      "Epoch 12/200, Loss: 0.5864006280899048\n",
      "Accuracy of the model on the validation data: 87.12 %\n",
      "Epoch 13/200, Loss: 0.5582262277603149\n",
      "Accuracy of the model on the validation data: 88.38 %\n",
      "Epoch 14/200, Loss: 0.5985015034675598\n",
      "Accuracy of the model on the validation data: 84.50 %\n",
      "Epoch 15/200, Loss: 0.5853773355484009\n",
      "Accuracy of the model on the validation data: 87.00 %\n",
      "Epoch 16/200, Loss: 0.5844574570655823\n",
      "Accuracy of the model on the validation data: 86.75 %\n",
      "Epoch 17/200, Loss: 0.6055036783218384\n",
      "Accuracy of the model on the validation data: 88.25 %\n",
      "Epoch 18/200, Loss: 0.5366379022598267\n",
      "Accuracy of the model on the validation data: 89.62 %\n",
      "Epoch 19/200, Loss: 0.6121795773506165\n",
      "Accuracy of the model on the validation data: 86.00 %\n",
      "Epoch 20/200, Loss: 0.5787416696548462\n",
      "Accuracy of the model on the validation data: 90.12 %\n",
      "Epoch 21/200, Loss: 0.5799649953842163\n",
      "Accuracy of the model on the validation data: 86.50 %\n",
      "Epoch 22/200, Loss: 0.5578305721282959\n",
      "Accuracy of the model on the validation data: 90.00 %\n",
      "Epoch 23/200, Loss: 0.575917661190033\n",
      "Accuracy of the model on the validation data: 88.62 %\n",
      "Epoch 24/200, Loss: 0.6335707902908325\n",
      "Accuracy of the model on the validation data: 83.25 %\n",
      "Epoch 25/200, Loss: 0.5975282788276672\n",
      "Accuracy of the model on the validation data: 90.62 %\n",
      "Epoch 26/200, Loss: 0.6475712060928345\n",
      "Accuracy of the model on the validation data: 91.00 %\n",
      "Epoch 27/200, Loss: 0.6203861236572266\n",
      "Accuracy of the model on the validation data: 87.88 %\n",
      "Epoch 28/200, Loss: 0.6634016036987305\n",
      "Accuracy of the model on the validation data: 89.00 %\n",
      "Epoch 29/200, Loss: 0.5492773056030273\n",
      "Accuracy of the model on the validation data: 91.25 %\n",
      "Epoch 30/200, Loss: 0.5656091570854187\n",
      "Accuracy of the model on the validation data: 84.12 %\n",
      "Epoch 31/200, Loss: 0.5723909735679626\n",
      "Accuracy of the model on the validation data: 90.75 %\n",
      "Epoch 32/200, Loss: 0.5828784704208374\n",
      "Accuracy of the model on the validation data: 90.75 %\n",
      "Epoch 33/200, Loss: 0.5439608693122864\n",
      "Accuracy of the model on the validation data: 91.50 %\n",
      "Epoch 34/200, Loss: 0.5685504078865051\n",
      "Accuracy of the model on the validation data: 91.62 %\n",
      "Epoch 35/200, Loss: 0.6158633828163147\n",
      "Accuracy of the model on the validation data: 91.38 %\n",
      "Epoch 36/200, Loss: 0.5462262630462646\n",
      "Accuracy of the model on the validation data: 90.25 %\n",
      "Epoch 37/200, Loss: 0.5563639998435974\n",
      "Accuracy of the model on the validation data: 91.38 %\n",
      "Epoch 38/200, Loss: 0.5996041297912598\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 39/200, Loss: 0.6033029556274414\n",
      "Accuracy of the model on the validation data: 92.00 %\n",
      "Epoch 40/200, Loss: 0.6019845008850098\n",
      "Accuracy of the model on the validation data: 89.62 %\n",
      "Epoch 41/200, Loss: 0.5910455584526062\n",
      "Accuracy of the model on the validation data: 92.12 %\n",
      "Epoch 42/200, Loss: 0.5116465091705322\n",
      "Accuracy of the model on the validation data: 91.25 %\n",
      "Epoch 43/200, Loss: 0.5969204306602478\n",
      "Accuracy of the model on the validation data: 91.12 %\n",
      "Epoch 44/200, Loss: 0.5723819732666016\n",
      "Accuracy of the model on the validation data: 91.50 %\n",
      "Epoch 45/200, Loss: 0.6168696880340576\n",
      "Accuracy of the model on the validation data: 92.25 %\n",
      "Epoch 46/200, Loss: 0.5950055122375488\n",
      "Accuracy of the model on the validation data: 92.00 %\n",
      "Epoch 47/200, Loss: 0.5441765785217285\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 48/200, Loss: 0.5407268404960632\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 49/200, Loss: 0.5536115169525146\n",
      "Accuracy of the model on the validation data: 89.50 %\n",
      "Epoch 50/200, Loss: 0.6038097143173218\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 51/200, Loss: 0.6126738786697388\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 52/200, Loss: 0.5090836882591248\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 53/200, Loss: 0.575206458568573\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 54/200, Loss: 0.6060820817947388\n",
      "Accuracy of the model on the validation data: 85.62 %\n",
      "Epoch 55/200, Loss: 0.5986171960830688\n",
      "Accuracy of the model on the validation data: 92.25 %\n",
      "Epoch 56/200, Loss: 0.5351396203041077\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 57/200, Loss: 0.6034559011459351\n",
      "Accuracy of the model on the validation data: 91.50 %\n",
      "Epoch 58/200, Loss: 0.5260137915611267\n",
      "Accuracy of the model on the validation data: 92.62 %\n",
      "Epoch 59/200, Loss: 0.5395272374153137\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 60/200, Loss: 0.5659830570220947\n",
      "Accuracy of the model on the validation data: 89.88 %\n",
      "Epoch 61/200, Loss: 0.577182948589325\n",
      "Accuracy of the model on the validation data: 92.00 %\n",
      "Epoch 62/200, Loss: 0.5638668537139893\n",
      "Accuracy of the model on the validation data: 92.88 %\n",
      "Epoch 63/200, Loss: 0.5975344181060791\n",
      "Accuracy of the model on the validation data: 91.62 %\n",
      "Epoch 64/200, Loss: 0.5975502133369446\n",
      "Accuracy of the model on the validation data: 91.12 %\n",
      "Epoch 65/200, Loss: 0.5630925297737122\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 66/200, Loss: 0.5996227860450745\n",
      "Accuracy of the model on the validation data: 92.00 %\n",
      "Epoch 67/200, Loss: 0.5424776673316956\n",
      "Accuracy of the model on the validation data: 91.12 %\n",
      "Epoch 68/200, Loss: 0.5760246515274048\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 69/200, Loss: 0.6090342998504639\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 70/200, Loss: 0.5949934720993042\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 71/200, Loss: 0.5801161527633667\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 72/200, Loss: 0.5156960487365723\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 73/200, Loss: 0.5764530301094055\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 74/200, Loss: 0.5569920539855957\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 75/200, Loss: 0.5043440461158752\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 76/200, Loss: 0.5555732250213623\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 77/200, Loss: 0.5520401000976562\n",
      "Accuracy of the model on the validation data: 92.25 %\n",
      "Epoch 78/200, Loss: 0.5735797882080078\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 79/200, Loss: 0.5375767350196838\n",
      "Accuracy of the model on the validation data: 91.62 %\n",
      "Epoch 80/200, Loss: 0.612930178642273\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 81/200, Loss: 0.5279488563537598\n",
      "Accuracy of the model on the validation data: 91.38 %\n",
      "Epoch 82/200, Loss: 0.5219320058822632\n",
      "Accuracy of the model on the validation data: 92.62 %\n",
      "Epoch 83/200, Loss: 0.541720986366272\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 84/200, Loss: 0.557097315788269\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 85/200, Loss: 0.5575436353683472\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 86/200, Loss: 0.5692538022994995\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 87/200, Loss: 0.5365433692932129\n",
      "Accuracy of the model on the validation data: 92.88 %\n",
      "Epoch 88/200, Loss: 0.5245723724365234\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 89/200, Loss: 0.5277794599533081\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 90/200, Loss: 0.6137521266937256\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 91/200, Loss: 0.6086438298225403\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 92/200, Loss: 0.6510533690452576\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 93/200, Loss: 0.6056106090545654\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 94/200, Loss: 0.5872666835784912\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 95/200, Loss: 0.5343990325927734\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 96/200, Loss: 0.5504439473152161\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 97/200, Loss: 0.5940747857093811\n",
      "Accuracy of the model on the validation data: 92.62 %\n",
      "Epoch 98/200, Loss: 0.5889883637428284\n",
      "Accuracy of the model on the validation data: 91.62 %\n",
      "Epoch 99/200, Loss: 0.5382962822914124\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 100/200, Loss: 0.5708104372024536\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 101/200, Loss: 0.5590740442276001\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 102/200, Loss: 0.6178932189941406\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 103/200, Loss: 0.6112580299377441\n",
      "Accuracy of the model on the validation data: 92.12 %\n",
      "Epoch 104/200, Loss: 0.5871102809906006\n",
      "Accuracy of the model on the validation data: 90.00 %\n",
      "Epoch 105/200, Loss: 0.5663565397262573\n",
      "Accuracy of the model on the validation data: 88.12 %\n",
      "Epoch 106/200, Loss: 0.5966326594352722\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 107/200, Loss: 0.5460882186889648\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 108/200, Loss: 0.6176523566246033\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 109/200, Loss: 0.5325900316238403\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 110/200, Loss: 0.5149044990539551\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 111/200, Loss: 0.5493719577789307\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 112/200, Loss: 0.5248839259147644\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 113/200, Loss: 0.5407814979553223\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 114/200, Loss: 0.5355691909790039\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 115/200, Loss: 0.5845885276794434\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 116/200, Loss: 0.5794985294342041\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 117/200, Loss: 0.583540678024292\n",
      "Accuracy of the model on the validation data: 92.12 %\n",
      "Epoch 118/200, Loss: 0.6335440874099731\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 119/200, Loss: 0.5661681890487671\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 120/200, Loss: 0.5494289398193359\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 121/200, Loss: 0.5562885403633118\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 122/200, Loss: 0.5822446346282959\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 123/200, Loss: 0.5361854434013367\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 124/200, Loss: 0.5783640146255493\n",
      "Accuracy of the model on the validation data: 94.12 %\n",
      "Epoch 125/200, Loss: 0.6078959107398987\n",
      "Accuracy of the model on the validation data: 92.88 %\n",
      "Epoch 126/200, Loss: 0.5706943273544312\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 127/200, Loss: 0.5718824863433838\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 128/200, Loss: 0.5535568594932556\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 129/200, Loss: 0.5529225468635559\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 130/200, Loss: 0.5380736589431763\n",
      "Accuracy of the model on the validation data: 90.62 %\n",
      "Epoch 131/200, Loss: 0.5297275185585022\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 132/200, Loss: 0.5993461012840271\n",
      "Accuracy of the model on the validation data: 91.00 %\n",
      "Epoch 133/200, Loss: 0.569951057434082\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 134/200, Loss: 0.5244584083557129\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 135/200, Loss: 0.5718427300453186\n",
      "Accuracy of the model on the validation data: 92.50 %\n",
      "Epoch 136/200, Loss: 0.6055717468261719\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 137/200, Loss: 0.5491210222244263\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 138/200, Loss: 0.5556248426437378\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 139/200, Loss: 0.5781447887420654\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 140/200, Loss: 0.5854886174201965\n",
      "Accuracy of the model on the validation data: 94.50 %\n",
      "Epoch 141/200, Loss: 0.5278074145317078\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 142/200, Loss: 0.5710829496383667\n",
      "Accuracy of the model on the validation data: 90.50 %\n",
      "Epoch 143/200, Loss: 0.5416954755783081\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 144/200, Loss: 0.607730507850647\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 145/200, Loss: 0.6025035381317139\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 146/200, Loss: 0.5902037620544434\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 147/200, Loss: 0.5175003409385681\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 148/200, Loss: 0.5844711065292358\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 149/200, Loss: 0.6280773878097534\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 150/200, Loss: 0.5593238472938538\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 151/200, Loss: 0.5184024572372437\n",
      "Accuracy of the model on the validation data: 93.25 %\n",
      "Epoch 152/200, Loss: 0.5490617752075195\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 153/200, Loss: 0.5591484308242798\n",
      "Accuracy of the model on the validation data: 94.00 %\n",
      "Epoch 154/200, Loss: 0.6173976063728333\n",
      "Accuracy of the model on the validation data: 89.38 %\n",
      "Epoch 155/200, Loss: 0.6004767417907715\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 156/200, Loss: 0.5580635070800781\n",
      "Accuracy of the model on the validation data: 92.75 %\n",
      "Epoch 157/200, Loss: 0.5446525812149048\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 158/200, Loss: 0.5415283441543579\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 159/200, Loss: 0.6069724559783936\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 160/200, Loss: 0.557375431060791\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 161/200, Loss: 0.6278698444366455\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 162/200, Loss: 0.58735191822052\n",
      "Accuracy of the model on the validation data: 92.25 %\n",
      "Epoch 163/200, Loss: 0.56204754114151\n",
      "Accuracy of the model on the validation data: 91.75 %\n",
      "Epoch 164/200, Loss: 0.616726279258728\n",
      "Accuracy of the model on the validation data: 94.00 %\n",
      "Epoch 165/200, Loss: 0.5999666452407837\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 166/200, Loss: 0.5367645025253296\n",
      "Accuracy of the model on the validation data: 94.00 %\n",
      "Epoch 167/200, Loss: 0.5579286813735962\n",
      "Accuracy of the model on the validation data: 94.12 %\n",
      "Epoch 168/200, Loss: 0.6466060280799866\n",
      "Accuracy of the model on the validation data: 94.00 %\n",
      "Epoch 169/200, Loss: 0.5794748067855835\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 170/200, Loss: 0.5201481580734253\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 171/200, Loss: 0.586522102355957\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 172/200, Loss: 0.6127012372016907\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 173/200, Loss: 0.5102567076683044\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 174/200, Loss: 0.5949601531028748\n",
      "Accuracy of the model on the validation data: 93.38 %\n",
      "Epoch 175/200, Loss: 0.6204196810722351\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 176/200, Loss: 0.574936032295227\n",
      "Accuracy of the model on the validation data: 91.62 %\n",
      "Epoch 177/200, Loss: 0.5896468162536621\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 178/200, Loss: 0.5710198879241943\n",
      "Accuracy of the model on the validation data: 94.12 %\n",
      "Epoch 179/200, Loss: 0.5664648413658142\n",
      "Accuracy of the model on the validation data: 92.38 %\n",
      "Epoch 180/200, Loss: 0.5171868801116943\n",
      "Accuracy of the model on the validation data: 93.50 %\n",
      "Epoch 181/200, Loss: 0.5575875043869019\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 182/200, Loss: 0.552725613117218\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 183/200, Loss: 0.5968213081359863\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 184/200, Loss: 0.5734457969665527\n",
      "Accuracy of the model on the validation data: 93.75 %\n",
      "Epoch 185/200, Loss: 0.5969105958938599\n",
      "Accuracy of the model on the validation data: 94.00 %\n",
      "Epoch 186/200, Loss: 0.5788675546646118\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 187/200, Loss: 0.6046695709228516\n",
      "Accuracy of the model on the validation data: 91.12 %\n",
      "Epoch 188/200, Loss: 0.5571619272232056\n",
      "Accuracy of the model on the validation data: 94.12 %\n",
      "Epoch 189/200, Loss: 0.6092642545700073\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 190/200, Loss: 0.586936891078949\n",
      "Accuracy of the model on the validation data: 94.38 %\n",
      "Epoch 191/200, Loss: 0.5866971015930176\n",
      "Accuracy of the model on the validation data: 92.25 %\n",
      "Epoch 192/200, Loss: 0.52055823802948\n",
      "Accuracy of the model on the validation data: 93.00 %\n",
      "Epoch 193/200, Loss: 0.5689792633056641\n",
      "Accuracy of the model on the validation data: 93.62 %\n",
      "Epoch 194/200, Loss: 0.5521854162216187\n",
      "Accuracy of the model on the validation data: 93.12 %\n",
      "Epoch 195/200, Loss: 0.5545985102653503\n",
      "Accuracy of the model on the validation data: 94.25 %\n",
      "Epoch 196/200, Loss: 0.6177549362182617\n",
      "Accuracy of the model on the validation data: 94.50 %\n",
      "Epoch 197/200, Loss: 0.5150008201599121\n",
      "Accuracy of the model on the validation data: 94.12 %\n",
      "Epoch 198/200, Loss: 0.5892965793609619\n",
      "Accuracy of the model on the validation data: 93.88 %\n",
      "Epoch 199/200, Loss: 0.570722222328186\n",
      "Accuracy of the model on the validation data: 94.62 %\n",
      "Epoch 200/200, Loss: 0.5719509720802307\n",
      "Accuracy of the model on the validation data: 93.50 %\n"
     ]
    }
   ],
   "source": [
    "class ImprovedRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes, num_layers=2, dropout_rate=0.2):\n",
    "        super(ImprovedRNN, self).__init__()\n",
    "        # 使用多层 LSTM，并添加 Dropout\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers=num_layers, \n",
    "                            batch_first=True, dropout=dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_size, num_classes)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x 是一个 PackedSequence\n",
    "        packed_output, (hidden, _) = self.lstm(x)\n",
    "        # 使用最后一个时间步的隐藏状态\n",
    "        out = self.fc(hidden[-1])\n",
    "        out = self.dropout(out)\n",
    "        out = torch.sigmoid(out).squeeze()\n",
    "        return out\n",
    "model = ImprovedRNN(input_size=80, hidden_size=128, num_classes=1).to(device)  # 适当调整参数\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.BCEWithLogitsLoss()  # 二元分类\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "num_epochs=200\n",
    "# 训练循环\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for sequence,label in train_loader:\n",
    "        sequence, label = sequence.to(device), label.to(device)\n",
    "        # 前向传播\n",
    "        label = label.float()\n",
    "        outputs = model(sequence)\n",
    "        loss = criterion(outputs, label)\n",
    "        # 反向传播和优化\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    model.eval()\n",
    "    total=0\n",
    "    correct=0\n",
    "    with torch.no_grad():\n",
    "        for sequences, labels in val_loader:\n",
    "            sequences, labels = sequences.to(device), labels.to(device)\n",
    "            outputs = model(sequences)\n",
    "            predicted = (outputs > 0.5).float()\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}')\n",
    "    print('Accuracy of the model on the validation data: %.2f %%' % accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"model_state_dict.pth\"\n",
    "torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_npy_data_with_labels(folder_path, label):\n",
    "    data_list = []  # 用于存储所有读取的数据\n",
    "    labels_list = []  # 用于存储所有的标签\n",
    "    for file in os.listdir(folder_path):\n",
    "        if file.endswith('.npy'):\n",
    "            file_path = os.path.join(folder_path, file)\n",
    "            data = np.load(file_path)\n",
    "            data_list.append(data)\n",
    "            \n",
    "    return data_list, labels_list\n",
    "test_data_raw,_ = load_npy_data_with_labels('test_data', 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_cropped=[matrix[:40] for matrix in test_data_raw]\n",
    "model.eval()\n",
    "test_data_cropped=torch.tensor(test_data_cropped)\n",
    "# 假设 test_loader 是您的无标签测试数据加载器\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in test_data_cropped:\n",
    "        data = data.to(device)  # 如果使用 GPU\n",
    "        outputs = model(data)\n",
    "        predicted_labels = (outputs > 0.5).float()\n",
    "        # 确保 predicted_labels 是一维数组\n",
    "        predicted_labels = predicted_labels.view(-1)\n",
    "        predictions.extend(predicted_labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 读取原始 CSV 文件\n",
    "original_df = pd.read_csv('test.csv')\n",
    "predictions_int = [int(x) for x in predictions]\n",
    "\n",
    "# 假设 `predictions` 是包含预测结果的列表\n",
    "# 检查预测结果的长度与原始 DataFrame 的长度是否一致\n",
    "if len(predictions) == len(original_df):\n",
    "    # 将预测结果作为 'label' 列的值\n",
    "    original_df['label'] = predictions_int\n",
    "\n",
    "    # 保存修改后的 DataFrame 到 CSV 文件\n",
    "    original_df.to_csv('test_with_predictions.csv', index=False)\n",
    "else:\n",
    "    print(\"Error: The length of the predictions does not match the original data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
